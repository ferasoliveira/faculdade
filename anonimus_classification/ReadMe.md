# ğŸ§  Projeto: Anonimus Classification

Este projeto explora diferentes algoritmos de classificaÃ§Ã£o em um conjunto de dados anÃ´nimo, utilizando tÃ©cnicas como **RegressÃ£o LogÃ­stica incremental (SGD)**, **Random Forest** e **SVM (SVC)**. O foco estÃ¡ na **avaliaÃ§Ã£o de desempenho por hiperparÃ¢metro**, com geraÃ§Ã£o automÃ¡tica de mÃ©tricas e grÃ¡ficos para anÃ¡lise comparativa.

---

## ğŸ“ Estrutura do Projeto
```
ğŸ“¦ Anonimus_Classification/
â”œâ”€â”€ model_logistic.py
â”œâ”€â”€ model_random_forest.py
â”œâ”€â”€ model_svc.py
â”œâ”€â”€ 02.csv # Base de dados de entrada
â”œâ”€â”€ results_logistic/ # Resultados do modelo SGDClassifier
â”œâ”€â”€ results_random_forest/ # Resultados do Random Forest
â”œâ”€â”€ results_svc/ # Resultados do SVC
â””â”€â”€ README.md
```

---

## âš™ï¸ Modelos Implementados

### 1. `SGDClassifier` (Logistic Regression)
- Treinamento incremental com `partial_fit`
- HiperparÃ¢metro variado: `C` (regularizaÃ§Ã£o inversa)
- MÃ©tricas analisadas por **Ã©poca** (atÃ© 500)
- Salva grÃ¡ficos `.png` e um CSV com as mÃ©tricas

### 2. `RandomForestClassifier`
- VariaÃ§Ã£o dos parÃ¢metros:
  - `n_estimators`: nÃºmero de Ã¡rvores
  - `max_depth`: profundidade mÃ¡xima das Ã¡rvores
- Coleta mÃ©tricas globais e tempo de treino

### 3. `SVC` (Support Vector Classifier)
- VariaÃ§Ã£o dos parÃ¢metros:
  - `C`: penalidade por erro
  - `kernel`: tipo de separaÃ§Ã£o (linear, rbf)
- Mede desempenho com base em prediÃ§Ã£o e `roc_auc`

---

## ğŸ“Š MÃ©tricas Avaliadas

- **Accuracy**
- **Precision**
- **Recall**
- **F1-Score**
- **ROC-AUC** (quando aplicÃ¡vel)
- **Tempo de execuÃ§Ã£o** por configuraÃ§Ã£o

Cada script salva as mÃ©tricas por configuraÃ§Ã£o em um arquivo `.csv` na respectiva pasta de resultados, alÃ©m de gerar grÃ¡ficos por mÃ©trica (no caso do SGD).

---

## â–¶ï¸ Como Executar

1. Instale as dependÃªncias:
```bash
pip install pandas scikit-learn matplotlib

``` 
ğŸ“Œ Objetivos do Projeto
Avaliar o impacto de hiperparÃ¢metros nos principais algoritmos de classificaÃ§Ã£o.

Gerar experimentos rastreÃ¡veis, com salvamento automÃ¡tico de grÃ¡ficos e mÃ©tricas.

Construir uma base sÃ³lida para comparaÃ§Ã£o de modelos em contextos supervisionados.

ğŸ§ª PrÃ³ximos Passos
Adicionar modelos de Boosting (XGBoost, LightGBM)

Implementar Grid Search ou Random Search automatizado

Realizar validaÃ§Ã£o cruzada k-fold

Empacotar como ferramenta interativa via CLI ou notebook

ğŸ§‘â€ğŸ’» Autor
Fernando Artur Souza de Oliveira